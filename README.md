# Binance Copy-Trade Lead Scraper

该项目提供一个面向阿里云函数计算（Function Compute，FC）自定义容器的 Scrapy + Playwright 爬虫，用于从币安复制跟单页面提取指定领航交易员的全部复制者信息。整个流程仅依赖网页渲染结果，不再调用币安公开 API。

## 功能特性

- **网页抓取**：利用 Playwright 渲染 `https://www.binance.com/zh-CN/copy-trading/lead-details/<lead_id>?timeRange=<window>` 页面，从页面脚本中解析复制者完整列表。
- **字段校验**：`ValidationPipeline` 会拒收为空或为零的数据，确保导出的快照可直接复核。
- **离线验证**：爬取结果写入 `output/copy_traders.json`，方便在 Supabase 入库前先人工检查。
- **Serverless 友好**：提供 Dockerfile、FastAPI 入口和 Serverless Devs 配置，可在阿里云 FC 中通过 HTTP 或定时任务触发。

## 目录结构

```
Dockerfile
README.md
app.py
money2x_spider/
  __init__.py
  items.py
  pipelines.py
  settings.py
  spiders/
    copy_trade.py
requirements.txt
s.yaml
scrapy.cfg
```

## 快速开始

1. **安装依赖**

   ```bash
   pip install -r requirements.txt
   playwright install chromium
   ```

2. **本地运行一次爬虫**（需网络可访问 Binance）

   ```bash
   scrapy crawl copy_trade \
     -a lead_url="https://www.binance.com/zh-CN/copy-trading/lead-details/4458914342020236800?timeRange=180D"
   ```

   运行结束后检查 `output/copy_traders.json`，确认字段均不为空且不为 0。

3. **部署到 FC**

   - 根据自身镜像仓库调整 `Dockerfile` 与 `s.yaml` 中的镜像地址；
   - 构建并推送镜像：

     ```bash
     docker build -t registry.cn-hangzhou.aliyuncs.com/<namespace>/binance-copytrade-metrics:latest .
     docker push registry.cn-hangzhou.aliyuncs.com/<namespace>/binance-copytrade-metrics:latest
     ```

   - 配置 `SUPABASE_URL`、`SUPABASE_KEY` 等环境变量后执行 `s deploy`；
   - `s.yaml` 默认每天上海时间 08:00 触发一次定时任务，也可以通过 HTTP 触发 `/invoke`。

## 核心组件说明

### `money2x_spider/spiders/copy_trade.py`

- 解析 `lead_url` 中的领航员 ID 与 `timeRange`；
- 使用 Playwright 渲染页面，等待网络静止后抓取最终 HTML；
- 从内嵌的应用数据脚本中递归查找复制交易员列表，转换成 `CopyTraderSnapshotItem`；
- 仅保留字段完整且非零的记录。

### `money2x_spider/pipelines.py`

- 校验每条记录的字段不为空、不为零；
- 将结果和生成时间写入 `output/copy_traders.json`，供后续导入 Supabase 时核对。

### `app.py`

- 暴露 FastAPI `/invoke` 端点：获取互斥锁后启动 Scrapy 爬虫，支持 `_settings_override_` 自定义运行参数；
- 使用 `/tmp/scrapy-job` 作为 Scrapy `JOBDIR`，支持在 FC 中断电后恢复状态；
- `/healthz` 用于存活探测。

## Supabase 表结构（参考）

如需直接写入 Supabase，可在 `pipelines.py` 中扩展逻辑，映射到以下示例表结构：

```sql
create table public.binance_spot_copy_trade_overview (
  id bigint generated by default as identity primary key,
  created_at timestamptz not null default now(),
  copiers integer,
  "AUM_usdt" numeric,
  "Leading_Balance_usdt" numeric,
  lead_trader_id bigint,
  scraped_date date,
  mock_copiers smallint
);

create table public.binance_spot_copy_trade (
  id bigint generated by default as identity primary key,
  created_at timestamptz not null default now(),
  "ROI" numeric,
  "PnL_usdt" numeric,
  performance_days integer not null,
  "Copier_PnL_usdt" numeric,
  "Sharpe_Ratio" numeric,
  "MDD" text,
  "Win_Rate" text,
  "Win_Days" integer,
  lead_trader_id bigint not null,
  scraped_date date not null,
  scraped_at timestamptz,
  constraint binance_spot_copy_trade_uid_scrapeddate_pdays_uk
    unique (lead_trader_id, scraped_date, performance_days)
);

create table public.binance_spot_copy_traders (
  duration bigint,
  user_id text not null,
  amount numeric,
  total_pnl numeric,
  total_roi numeric,
  created_date date not null,
  primary key (user_id, created_date)
);
```

## 常见问题

- **无法访问 Binance**：确认部署环境具备外网能力，如需代理可在环境变量中配置 Playwright 浏览器的代理参数。
- **字段缺失被丢弃**：`ValidationPipeline` 会在遇到空值或 0 时抛出 `DropItem`；必要时请先调整数据清洗逻辑再入库。
- **是否具备联网能力**：开发容器默认可以直接访问互联网（包括 Binance 及依赖安装源），但在某些企业或云上环境中仍可能受到防火墙与出口策略限制，部署前需先确认网络策略符合抓取需求。

